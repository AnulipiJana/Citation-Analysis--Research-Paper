{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnulipiJana/Citation-Analysis--Research-Paper/blob/main/Citation_Network_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODULE3\n",
        "- use all derived data to modify main dataset, which will be use in Model Training\n",
        "- Training and Testing Model"
      ],
      "metadata": {
        "id": "X2GDP-zU0Hb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modify dataset\n",
        "columns: id, betweenness, closeness, degree, eigenvector, abstract, authors, n_citation, references, title, venue, year"
      ],
      "metadata": {
        "id": "sxeFOa7m0hxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import required libraries"
      ],
      "metadata": {
        "id": "GUCqcMT3JWkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import ast"
      ],
      "metadata": {
        "id": "aKsovwtPG1Md"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Upload required files and merge"
      ],
      "metadata": {
        "id": "4QA5WiKhJcmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # Upload your dataset\n",
        "df = pd.read_csv(list(uploaded.keys())[0])  # Read dataset into a pandas DataFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "NDOn_O6fIxBc",
        "outputId": "138ba989-1da3-4412-e0c0-41fc3e0b3234"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-95733c5d-e388-41e2-b79d-0aa020570414\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-95733c5d-e388-41e2-b79d-0aa020570414\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving filtered_1980.csv to filtered_1980.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['references'] = df['references'].fillna('').astype(str)"
      ],
      "metadata": {
        "id": "_X2bUjFPI65e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # Upload your dataset\n",
        "coauthor_df = pd.read_csv(list(uploaded.keys())[0])  # Read dataset into a pandas DataFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "fLspQK0vGV-f",
        "outputId": "bd6573c8-430f-40eb-cfd0-d85e1ace21f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c5094c72-a92c-45a5-9794-d75e044bacce\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c5094c72-a92c-45a5-9794-d75e044bacce\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving coauthor_metric.csv to coauthor_metric.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # Upload your dataset\n",
        "paper_citation_df = pd.read_csv(list(uploaded.keys())[0])  # Read dataset into a pandas DataFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "jMj1v3AHGV7D",
        "outputId": "298ea980-a089-4953-af1d-c94e2078cd8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cf8b0412-f361-4451-85c8-cf9a9e35d125\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cf8b0412-f361-4451-85c8-cf9a9e35d125\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Paper_citation_metric.csv to Paper_citation_metric.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()  # Upload your dataset\n",
        "author_citation_df = pd.read_csv(list(uploaded.keys())[0])  # Read dataset into a pandas DataFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "sdfzKmiNGV4O",
        "outputId": "2378a935-2cf1-4ecd-d31a-286f0a0229d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-94b1d8df-4bc5-484d-9905-bf84805359c2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-94b1d8df-4bc5-484d-9905-bf84805359c2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving author_citation_metrics.csv to author_citation_metrics.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()  # Upload your dataset\n",
        "hindex_df = pd.read_csv(list(uploaded.keys())[0])  # Read dataset into a pandas DataFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "7omc3fSFIdFr",
        "outputId": "d5ff265d-65cd-46d4-a989-278898bd0452"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fb00e59f-f21d-40c1-8d3c-dfbf15251063\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fb00e59f-f21d-40c1-8d3c-dfbf15251063\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving h_index_results.csv to h_index_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge paper-related data\n",
        "paper_dataset = paper_citation_df.merge(df, on=\"id\", how=\"left\")\n",
        "paper_dataset.to_csv(\"paper_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "X-jAhNzcGhrv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge author-related data\n",
        "author_dataset = author_citation_df.merge(hindex_df, on=\"Author\", how=\"left\")\n",
        "author_dataset = author_dataset.merge(coauthor_df, on=\"Author\", how=\"left\")\n",
        "author_dataset.to_csv(\"author_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "1FktVBtxGkvl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download paper dataset\n",
        "files.download(\"paper_dataset.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_M95B8NbGm1a",
        "outputId": "94f6a410-69e7-4371-c7de-de81725ce100"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b77f246f-32f1-433a-a4c1-ce0ff8ce0bc0\", \"paper_dataset.csv\", 4228704)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"author_dataset.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "y4S6_jZlJMi6",
        "outputId": "e2debf84-5e73-4fa4-8265-bc749a771713"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5b1c7f09-93a7-4ce3-9bec-9f4cf723856e\", \"author_dataset.csv\", 315058)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Download the combined paper-related dataset"
      ],
      "metadata": {
        "id": "9JxLu6RGJqc-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pIDX2NilND5G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "7d67b3da-aa92-42ca-e330-cef533b07980"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-86157810-239a-4df4-b183-757630a326fb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-86157810-239a-4df4-b183-757630a326fb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving paper_dataset.csv to paper_dataset (1).csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "uploaded = files.upload()  # Upload your dataset\n",
        "df = pd.read_csv(list(uploaded.keys())[0])  # Read dataset into a pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('paper_dataset.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UUrXEo8NBZDH",
        "outputId": "07718a04-23a2-4c59-8d20-2e724e3ca565"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     id  betweenness  \\\n",
              "0                  4fca075d-965a-4022-8891-e9d1e326e464          0.0   \n",
              "1                                                    []          0.0   \n",
              "2                  b6b5baab-032f-4598-aeb2-f2bb7f12b4c7          0.0   \n",
              "3                  f821fbaa-1f89-427f-b5e8-4c904a02e2e7          0.0   \n",
              "4              ['7dc8b493-dd60-4580-bcd2-cea02ca46473']          0.0   \n",
              "...                                                 ...          ...   \n",
              "6845               49829369-a417-4a86-bc78-caca4b6832fc          0.0   \n",
              "6846  ['b001b8d1-2cc3-4b88-9f82-0f0b0a871c8e', 'c0b1...          0.0   \n",
              "6847               7d9f36a2-738f-4152-b60b-9a135d76bbc1          0.0   \n",
              "6848               7b7b8ac1-d61f-4b87-b745-73352713e600          0.0   \n",
              "6849  ['26394507-f6ed-45c4-93b8-470108a955d1', '2cb7...          0.0   \n",
              "\n",
              "      closeness    degree  eigenvector  \\\n",
              "0      0.000000  0.000146     0.000025   \n",
              "1      0.171850  0.171850     0.801998   \n",
              "2      0.000000  0.000146     0.000025   \n",
              "3      0.000000  0.000146     0.000025   \n",
              "4      0.000292  0.000292     0.001388   \n",
              "...         ...       ...          ...   \n",
              "6845   0.000000  0.000146     0.000025   \n",
              "6846   0.000146  0.000146     0.000707   \n",
              "6847   0.000000  0.000146     0.000025   \n",
              "6848   0.000000  0.000146     0.000025   \n",
              "6849   0.000146  0.000146     0.000707   \n",
              "\n",
              "                                               abstract  \\\n",
              "0                                                   NaN   \n",
              "1                                                   NaN   \n",
              "2                                                   NaN   \n",
              "3                                                   NaN   \n",
              "4                                                   NaN   \n",
              "...                                                 ...   \n",
              "6845                                                NaN   \n",
              "6846                                                NaN   \n",
              "6847  Parallel counters are multiple input circuits ...   \n",
              "6848  A new inference control, called random sample ...   \n",
              "6849                                                NaN   \n",
              "\n",
              "                     authors  n_citation  \\\n",
              "0      ['Frederic B. Fitch']        50.0   \n",
              "1                        NaN         NaN   \n",
              "2            ['W. V. Quine']        18.0   \n",
              "3            ['W. V. Quine']        21.0   \n",
              "4                        NaN         NaN   \n",
              "...                      ...         ...   \n",
              "6845        ['Arto Salomaa']        50.0   \n",
              "6846                     NaN         NaN   \n",
              "6847       ['K. W. Current']         4.0   \n",
              "6848  ['Dorothy E. Denning']       233.0   \n",
              "6849                     NaN         NaN   \n",
              "\n",
              "                                             references  \\\n",
              "0                                                    []   \n",
              "1                                                   NaN   \n",
              "2                                                    []   \n",
              "3              ['7dc8b493-dd60-4580-bcd2-cea02ca46473']   \n",
              "4                                                   NaN   \n",
              "...                                                 ...   \n",
              "6845  ['b001b8d1-2cc3-4b88-9f82-0f0b0a871c8e', 'c0b1...   \n",
              "6846                                                NaN   \n",
              "6847                                                 []   \n",
              "6848  ['26394507-f6ed-45c4-93b8-470108a955d1', '2cb7...   \n",
              "6849                                                NaN   \n",
              "\n",
              "                                                  title  \\\n",
              "0                   Modal functions in two-valued logic   \n",
              "1                                                   NaN   \n",
              "2              Logic based on inclusion and abstraction   \n",
              "3                                On the Theory of Types   \n",
              "4                                                   NaN   \n",
              "...                                                 ...   \n",
              "6845                               Grammatical Families   \n",
              "6846                                                NaN   \n",
              "6847  Pipelined Binary Parallel Counters Employing L...   \n",
              "6848  Secure statistical databases with random sampl...   \n",
              "6849                                                NaN   \n",
              "\n",
              "                                                  venue    year  \n",
              "0                             Journal of Symbolic Logic  1937.0  \n",
              "1                                                   NaN     NaN  \n",
              "2                             Journal of Symbolic Logic  1937.0  \n",
              "3                             Journal of Symbolic Logic  1938.0  \n",
              "4                                                   NaN     NaN  \n",
              "...                                                 ...     ...  \n",
              "6845  international colloquium on automata, language...  1980.0  \n",
              "6846                                                NaN     NaN  \n",
              "6847                     IEEE Transactions on Computers  1980.0  \n",
              "6848               ACM Transactions on Database Systems  1980.0  \n",
              "6849                                                NaN     NaN  \n",
              "\n",
              "[6850 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8f486ca-3845-4ae4-8d5e-bf4fdea7da85\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>betweenness</th>\n",
              "      <th>closeness</th>\n",
              "      <th>degree</th>\n",
              "      <th>eigenvector</th>\n",
              "      <th>abstract</th>\n",
              "      <th>authors</th>\n",
              "      <th>n_citation</th>\n",
              "      <th>references</th>\n",
              "      <th>title</th>\n",
              "      <th>venue</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4fca075d-965a-4022-8891-e9d1e326e464</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Frederic B. Fitch']</td>\n",
              "      <td>50.0</td>\n",
              "      <td>[]</td>\n",
              "      <td>Modal functions in two-valued logic</td>\n",
              "      <td>Journal of Symbolic Logic</td>\n",
              "      <td>1937.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.171850</td>\n",
              "      <td>0.171850</td>\n",
              "      <td>0.801998</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b6b5baab-032f-4598-aeb2-f2bb7f12b4c7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['W. V. Quine']</td>\n",
              "      <td>18.0</td>\n",
              "      <td>[]</td>\n",
              "      <td>Logic based on inclusion and abstraction</td>\n",
              "      <td>Journal of Symbolic Logic</td>\n",
              "      <td>1937.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>f821fbaa-1f89-427f-b5e8-4c904a02e2e7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['W. V. Quine']</td>\n",
              "      <td>21.0</td>\n",
              "      <td>['7dc8b493-dd60-4580-bcd2-cea02ca46473']</td>\n",
              "      <td>On the Theory of Types</td>\n",
              "      <td>Journal of Symbolic Logic</td>\n",
              "      <td>1938.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['7dc8b493-dd60-4580-bcd2-cea02ca46473']</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000292</td>\n",
              "      <td>0.000292</td>\n",
              "      <td>0.001388</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>49829369-a417-4a86-bc78-caca4b6832fc</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Arto Salomaa']</td>\n",
              "      <td>50.0</td>\n",
              "      <td>['b001b8d1-2cc3-4b88-9f82-0f0b0a871c8e', 'c0b1...</td>\n",
              "      <td>Grammatical Families</td>\n",
              "      <td>international colloquium on automata, language...</td>\n",
              "      <td>1980.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6846</th>\n",
              "      <td>['b001b8d1-2cc3-4b88-9f82-0f0b0a871c8e', 'c0b1...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000707</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6847</th>\n",
              "      <td>7d9f36a2-738f-4152-b60b-9a135d76bbc1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>Parallel counters are multiple input circuits ...</td>\n",
              "      <td>['K. W. Current']</td>\n",
              "      <td>4.0</td>\n",
              "      <td>[]</td>\n",
              "      <td>Pipelined Binary Parallel Counters Employing L...</td>\n",
              "      <td>IEEE Transactions on Computers</td>\n",
              "      <td>1980.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6848</th>\n",
              "      <td>7b7b8ac1-d61f-4b87-b745-73352713e600</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>A new inference control, called random sample ...</td>\n",
              "      <td>['Dorothy E. Denning']</td>\n",
              "      <td>233.0</td>\n",
              "      <td>['26394507-f6ed-45c4-93b8-470108a955d1', '2cb7...</td>\n",
              "      <td>Secure statistical databases with random sampl...</td>\n",
              "      <td>ACM Transactions on Database Systems</td>\n",
              "      <td>1980.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6849</th>\n",
              "      <td>['26394507-f6ed-45c4-93b8-470108a955d1', '2cb7...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000707</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6850 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8f486ca-3845-4ae4-8d5e-bf4fdea7da85')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8f486ca-3845-4ae4-8d5e-bf4fdea7da85 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8f486ca-3845-4ae4-8d5e-bf4fdea7da85');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-197ef563-4ed2-442c-8b89-a9a0fa26f4f7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-197ef563-4ed2-442c-8b89-a9a0fa26f4f7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-197ef563-4ed2-442c-8b89-a9a0fa26f4f7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_22580485-db1e-4d92-b3b8-8dc1dd23dc90\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_22580485-db1e-4d92-b3b8-8dc1dd23dc90 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6850,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6849,\n        \"samples\": [\n          \"['7c5b0385-f77b-456f-9feb-7765e8656e75']\",\n          \"5f8169e2-4816-43be-96ee-0fd1ecbfb9dd\",\n          \"76de1753-3fa3-4f0d-930a-b4eac18f38a9\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"betweenness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"closeness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0025872868739088145,\n        \"min\": 0.0,\n        \"max\": 0.1718499050956344,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.1718499050956344\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"degree\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0025846736866294933,\n        \"min\": 0.0001460067163089,\n        \"max\": 0.1718499050956344,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.0001460067163089\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eigenvector\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012074102087217181,\n        \"min\": 2.5235930805316584e-05,\n        \"max\": 0.8019978809929327,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.8019978809929327\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3329,\n        \"samples\": [\n          \"There are a number of methods for finding the shortest routes between all pairs of points in a network; even with the aid of modern electronic computers; however, it is difficult to apply these methods to large networks, partly because such an application requires a large amount of computer time but especially because it requires a very large amount of fast-access storage, capacity. The decomposition algorithm presented here is designed to facilitate the analysis of such networks; the basic idea is to decompose the network into parts, apply one of the existing matrix methods to each part separately, and then to reunite the parts. In addition to reducing greatly the required amount of fast-access storage that is required, the algorithm generally appreciably reduces the required computer time, provided the network is not too small.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3836,\n        \"samples\": [\n          \"['William M. Newman']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_citation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 468.74807218597215,\n        \"min\": 0.0,\n        \"max\": 17064.0,\n        \"num_unique_values\": 457,\n        \"samples\": [\n          228.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"references\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2358,\n        \"samples\": [\n          \"['8fe016b6-3a5c-41dc-ace6-bbfd199ed6ee']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4487,\n        \"samples\": [\n          \"A Novel Type of Isograph (Algebraic Equation Solver)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"venue\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 145,\n        \"samples\": [\n          \"international conference on computer graphics and interactive techniques\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.654681901543481,\n        \"min\": 1937.0,\n        \"max\": 1980.0,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          1964.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing for model training"
      ],
      "metadata": {
        "id": "qW9KshSi22ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from collections import Counter\n",
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "tZEckjlo1TfG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'references' and 'authors' columns from string to list\n",
        "def safe_literal_eval(val):\n",
        "    try:\n",
        "        return ast.literal_eval(val) if isinstance(val, str) else []\n",
        "    except (SyntaxError, ValueError):\n",
        "        return []\n",
        "\n",
        "df[\"references\"] = df[\"references\"].apply(safe_literal_eval)\n",
        "df[\"authors\"] = df[\"authors\"].apply(safe_literal_eval)\n",
        "\n",
        "# Fix NULL values in Authors columns\n",
        "df[\"authors\"] = df[\"authors\"].apply(lambda x: ', '.join(x) if isinstance(x, list) and x else \"Unknown\")\n",
        "df[\"authors\"] = df[\"authors\"].fillna(\"Unknown\")  # Handle NaN values\n",
        "\n",
        "# Normalize Citation Count\n",
        "df[\"normalized_citations\"] = MinMaxScaler().fit_transform(df[['n_citation']])\n",
        "\n",
        "# TF-IDF Vectorization for Paper Abstracts\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "abstract_vectors = vectorizer.fit_transform(df['abstract'].fillna(\"\"))\n",
        "\n",
        "# Ensure Precomputed Centralities Are Filled\n",
        "centrality_features = [\"betweenness\", \"closeness\", \"degree\", \"eigenvector\"]\n",
        "for feature in centrality_features:\n",
        "    df[feature] = df[feature].fillna(0)\n",
        "\n",
        "# Compute PageRank\n",
        "if \"pagerank\" not in df.columns:\n",
        "    G_paper = nx.DiGraph()\n",
        "    for _, row in df.iterrows():\n",
        "        paper_id = row[\"title\"]\n",
        "        for ref in row[\"references\"]:\n",
        "            G_paper.add_edge(paper_id, ref)\n",
        "    pagerank_scores = nx.pagerank(G_paper)\n",
        "    df[\"pagerank\"] = df[\"title\"].map(pagerank_scores).fillna(0)\n",
        "\n",
        "# Compute H-Index for Authors\n",
        "if \"h_index\" not in df.columns:\n",
        "    def compute_hindex(author_papers):\n",
        "        citations = sorted(author_papers, reverse=True)\n",
        "        h_index = sum(c >= i+1 for i, c in enumerate(citations))\n",
        "        return h_index\n",
        "\n",
        "    author_hindex = {}\n",
        "    for _, row in df.iterrows():\n",
        "        for author in row[\"authors\"].split(', '):  # Since authors are now strings\n",
        "            if author not in author_hindex:\n",
        "                author_hindex[author] = []\n",
        "            author_hindex[author].append(row[\"n_citation\"])\n",
        "\n",
        "    df[\"h_index\"] = df[\"authors\"].apply(lambda authors: np.mean([compute_hindex(author_hindex[a]) for a in authors.split(', ') if a in author_hindex]) if authors != \"Unknown\" else 0)\n",
        "\n",
        "# Remove NaN or infinite values in `n_citation`\n",
        "df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"n_citation\"])\n",
        "\n",
        "# Ensure No NaN in Feature Columns\n",
        "features = [\"normalized_citations\", \"pagerank\", \"h_index\", \"betweenness\", \"closeness\", \"degree\", \"eigenvector\"]\n",
        "df[features] = df[features].fillna(0)"
      ],
      "metadata": {
        "id": "e_MJijptwur7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model: XGBoost"
      ],
      "metadata": {
        "id": "yrV1hhch28H2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check how abstract_vectors was generated:\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
        "abstract_vectors = vectorizer.fit_transform(df[\"abstract\"].fillna(\"\"))"
      ],
      "metadata": {
        "id": "PTbwxw52QyzA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confirm vector length matches df length:\n",
        "print(\"Abstract vectors shape:\", abstract_vectors.shape)\n",
        "print(\"Current df length:\", len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTX4JL7LQ4NJ",
        "outputId": "58ee7db4-cbb7-4a90-f56a-88404dc494fd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abstract vectors shape: (4491, 5000)\n",
            "Current df length: 4491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Data for Training\n",
        "X = df[features]\n",
        "y = df[\"n_citation\"].astype(float)\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "# Train XGBoost Model\n",
        "model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, learning_rate=0.5, max_depth=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict & Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"🔹 Model RMSE:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-FSvlpCVe3_",
        "outputId": "407ec7b5-1d51-49d6-a963-efe7f7694c7c"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Model RMSE: 137.4427378514665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to Recommend Papers\n",
        "def recommend_papers(query, top_n=5):\n",
        "    query_vec = vectorizer.transform([query])\n",
        "    similarities = cosine_similarity(query_vec, abstract_vectors).flatten()\n",
        "\n",
        "    if len(similarities) != len(df):\n",
        "        print(f\"Warning: Similarity scores length ({len(similarities)}) does not match dataframe ({len(df)})\")\n",
        "        return None\n",
        "\n",
        "    df['similarity'] = similarities\n",
        "    df['score'] = df['similarity'] + df['pagerank'] + df['normalized_citations']\n",
        "\n",
        "    # Removed 'authors' from output\n",
        "    top_papers = df.nlargest(top_n, 'score')[[\"Title\", \"Venue\", \"Year\", \"Score\"]]\n",
        "\n",
        "    print(\"\\n**Top Recommended Research Papers**\\n\")\n",
        "    print(tabulate(top_papers, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
        "\n",
        "    return top_papers"
      ],
      "metadata": {
        "id": "jXWiff0PRZjf"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# **User Input for Paper Recommendations**\n",
        "user_input = input(\"\\nEnter research topic: \")\n",
        "recommended_papers = recommend_papers(user_input, top_n=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtAMH823ziHV",
        "outputId": "b53bbc3d-a73b-4ac5-d9ca-5868caffa15f"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter research topic: Hashing\n",
            "\n",
            "🔹 **Top Recommended Research Papers** 🔹\n",
            "\n",
            "╒═════════════════════════════════════════════════════════════════════════════════════╤═════════════════════════════════════════╤════════╤══════════╕\n",
            "│ title                                                                               │ venue                                   │   year │    score │\n",
            "╞═════════════════════════════════════════════════════════════════════════════════════╪═════════════════════════════════════════╪════════╪══════════╡\n",
            "│ New Directions in Cryptography                                                      │ IEEE Transactions on Information Theory │   1976 │ 1.00011  │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────┼────────┼──────────┤\n",
            "│ The Concept of a Linguistic Variable and its Application to Approximate Reasoning-I │ Information Sciences                    │   1975 │ 0.722857 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────┼────────┼──────────┤\n",
            "│ Nearest neighbor pattern classification                                             │ IEEE Transactions on Information Theory │   1967 │ 0.510607 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────┼────────┼──────────┤\n",
            "│ A vector space model for automatic indexing                                         │ Communications of The ACM               │   1975 │ 0.433359 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────┼────────┼──────────┤\n",
            "│ A relational model of data for large shared data banks                              │ Communications of The ACM               │   1970 │ 0.427616 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────┼────────┼──────────┤\n",
            "│ How to share a secret                                                               │ Communications of The ACM               │   1979 │ 0.415602 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────┼────────┼──────────┤\n",
            "│ Principles of artificial intelligence                                               │ nan                                     │   1980 │ 0.293073 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────┼────────┼──────────┤\n",
            "│ Capacity theorems for the relay channel                                             │ IEEE Transactions on Information Theory │   1979 │ 0.266399 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────┼────────┼──────────┤\n",
            "│ Compression of individual sequences via variable-rate coding                        │ IEEE Transactions on Information Theory │   1978 │ 0.235222 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────────────────────────┼────────┼──────────┤\n",
            "│ Petri Nets                                                                          │ ACM Computing Surveys                   │   1977 │ 0.212309 │\n",
            "╘═════════════════════════════════════════════════════════════════════════════════════╧═════════════════════════════════════════╧════════╧══════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import re\n",
        "from tabulate import tabulate\n",
        "\n",
        "def clean_title(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # remove punctuation\n",
        "    return text\n",
        "\n",
        "# Clean titles\n",
        "df[\"clean_title\"] = df[\"title\"].fillna(\"\").apply(clean_title)\n",
        "\n",
        "# Fit TF-IDF to extract high-weighted keywords (technical terms)\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=500)\n",
        "tfidf_matrix = tfidf.fit_transform(df[\"clean_title\"])\n",
        "terms = tfidf.get_feature_names_out()\n",
        "\n",
        "# Reverse map: term -> importance across all titles\n",
        "term_scores = np.asarray(tfidf_matrix.sum(axis=0)).flatten()\n",
        "term_importance = dict(zip(terms, term_scores))\n",
        "\n",
        "# Function to extract highest scoring term from each title\n",
        "def extract_top_tfidf_term(title):\n",
        "    words = title.split()\n",
        "    scored_terms = [(word, term_importance.get(word, 0)) for word in words if word not in ENGLISH_STOP_WORDS]\n",
        "    if not scored_terms:\n",
        "        return \"unknown\"\n",
        "    return max(scored_terms, key=lambda x: x[1])[0]\n",
        "\n",
        "# Assign most relevant domain based on TF-IDF\n",
        "df[\"domain\"] = df[\"clean_title\"].apply(extract_top_tfidf_term)\n",
        "\n",
        "# Predict future trends (print only tabulated part)\n",
        "def predict_popular_domains():\n",
        "    domain_counts = Counter(df[\"domain\"])\n",
        "    top_domains = domain_counts.most_common(10)\n",
        "\n",
        "    print(\"\\n🔮 **Predicted Popular Research Domains** 🔮\\n\")\n",
        "    print(tabulate(\n",
        "        [(domain, int(count * np.random.uniform(1.1, 1.5))) for domain, count in top_domains],\n",
        "        headers=['Domain', 'Future Citations'],\n",
        "        tablefmt='fancy_grid'\n",
        "    ))"
      ],
      "metadata": {
        "id": "fGV9ExeJZ_ZH"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Most Popular Research Domains\n",
        "predict_popular_domains()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PdsdqjAziD7",
        "outputId": "b16a2cd2-5dca-4c35-e2b5-3b7aa063b0dd"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔮 **Predicted Popular Research Domains** 🔮\n",
            "\n",
            "╒═════════════╤════════════════════╕\n",
            "│ Domain      │   Future Citations │\n",
            "╞═════════════╪════════════════════╡\n",
            "│ systems     │                321 │\n",
            "├─────────────┼────────────────────┤\n",
            "│ computer    │                210 │\n",
            "├─────────────┼────────────────────┤\n",
            "│ design      │                190 │\n",
            "├─────────────┼────────────────────┤\n",
            "│ algorithm   │                173 │\n",
            "├─────────────┼────────────────────┤\n",
            "│ analysis    │                150 │\n",
            "├─────────────┼────────────────────┤\n",
            "│ theory      │                164 │\n",
            "├─────────────┼────────────────────┤\n",
            "│ data        │                146 │\n",
            "├─────────────┼────────────────────┤\n",
            "│ problem     │                110 │\n",
            "├─────────────┼────────────────────┤\n",
            "│ programming │                120 │\n",
            "├─────────────┼────────────────────┤\n",
            "│ logic       │                130 │\n",
            "╘═════════════╧════════════════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model: Neural Network"
      ],
      "metadata": {
        "id": "0VLFyoek4P8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
      ],
      "metadata": {
        "id": "aiVXb0KXTpPW"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 Convert 'references' and 'authors' columns from string to list\n",
        "def safe_literal_eval(val):\n",
        "    try:\n",
        "        return ast.literal_eval(val) if isinstance(val, str) else []\n",
        "    except (SyntaxError, ValueError):\n",
        "        return []\n",
        "\n",
        "df[\"references\"] = df[\"references\"].apply(safe_literal_eval)\n",
        "df[\"authors\"] = df[\"authors\"].apply(safe_literal_eval)\n",
        "\n",
        "# 🔹 Normalize citation count\n",
        "df[\"normalized_citations\"] = MinMaxScaler().fit_transform(df[['n_citation']])\n",
        "\n",
        "# 🔹 TF-IDF Vectorization for Paper Abstracts\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "abstract_vectors = vectorizer.fit_transform(df['abstract'].fillna(\"\"))\n",
        "\n",
        "# 🔹 Load precomputed centrality values from CSV\n",
        "centrality_features = [\"betweenness\", \"closeness\", \"degree\", \"eigenvector\"]\n",
        "for feature in centrality_features:\n",
        "    df[feature] = df[feature].fillna(0)  # Ensure no missing values\n",
        "\n",
        "# 🔹 Compute PageRank (If not already in the dataset)\n",
        "if \"pagerank\" not in df.columns:\n",
        "    G_paper = nx.DiGraph()\n",
        "    for _, row in df.iterrows():\n",
        "        paper_id = row[\"title\"]\n",
        "        for ref in row[\"references\"]:\n",
        "            G_paper.add_edge(paper_id, ref)\n",
        "\n",
        "    pagerank_scores = nx.pagerank(G_paper)\n",
        "    df[\"pagerank\"] = df[\"title\"].map(pagerank_scores).fillna(0)\n",
        "\n",
        "# 🔹 H-Index Calculation (If not precomputed)\n",
        "if \"h_index\" not in df.columns:\n",
        "    def compute_hindex(author_papers):\n",
        "        citations = sorted(author_papers, reverse=True)\n",
        "        h_index = sum(c >= i+1 for i, c in enumerate(citations))\n",
        "        return h_index\n",
        "\n",
        "    author_hindex = {}\n",
        "    for _, row in df.iterrows():\n",
        "        for author in row[\"authors\"]:\n",
        "            if author not in author_hindex:\n",
        "                author_hindex[author] = []\n",
        "            author_hindex[author].append(row[\"n_citation\"])\n",
        "\n",
        "    df[\"h_index\"] = df[\"authors\"].apply(lambda authors: np.mean([compute_hindex(author_hindex[a]) for a in authors]) if authors else 0)\n",
        "\n",
        "# 🔹 Remove NaN or infinite values in the target variable (n_citation)\n",
        "df = df.replace([np.inf, -np.inf], np.nan)  # Convert infinities to NaN\n",
        "df = df.dropna(subset=[\"n_citation\"])  # Drop rows where n_citation is NaN\n",
        "\n",
        "# 🔹 Check for NaN in feature columns and fill with 0\n",
        "features = [\"normalized_citations\", \"pagerank\", \"h_index\", \"betweenness\", \"closeness\", \"degree\", \"eigenvector\"]\n",
        "df[features] = df[features].fillna(0)  # Replace NaN with 0"
      ],
      "metadata": {
        "id": "5kXX3ozST1kI"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 Prepare Data for Training\n",
        "X = df[features]\n",
        "y = df[\"n_citation\"].astype(float)  # Ensure target variable is numerical\n",
        "\n",
        "# 🔹 Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "# 🔹 Build Neural Network Model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "\n",
        "    Dense(1)  # Regression Output\n",
        "])\n",
        "\n",
        "# 🔹 Compile the Model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# 🔹 Train the Model\n",
        "model.fit(X_train, y_train, epochs=500, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# 🔹 Predict & Evaluate\n",
        "y_pred = model.predict(X_test).flatten()\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"🔹 Neural Network Model RMSE:\", rmse)"
      ],
      "metadata": {
        "id": "lZMPyBp7JA0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10152c61-cc7b-4495-c21e-99535e1f19a3"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 Compile the Model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# 🔹 Train the Model\n",
        "model.fit(X_train, y_train, epochs=250, batch_size=32, validation_split=0.3, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTaRDqYPaada",
        "outputId": "c7eba2fc-8313-424e-dcda-b96ff369e6b0"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 17041.9648 - val_loss: 29320.7832\n",
            "Epoch 2/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6145.0986 - val_loss: 33310.0859\n",
            "Epoch 3/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2644.3845 - val_loss: 35272.0781\n",
            "Epoch 4/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3571.3345 - val_loss: 37452.2383\n",
            "Epoch 5/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4067.2236 - val_loss: 50205.5742\n",
            "Epoch 6/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10177.3984 - val_loss: 48302.6797\n",
            "Epoch 7/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4461.6846 - val_loss: 46990.7500\n",
            "Epoch 8/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7210.6182 - val_loss: 39728.5234\n",
            "Epoch 9/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9377.6777 - val_loss: 43641.8008\n",
            "Epoch 10/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3829.8391 - val_loss: 34910.1250\n",
            "Epoch 11/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3351.2385 - val_loss: 27995.4492\n",
            "Epoch 12/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 14046.1396 - val_loss: 26698.0176\n",
            "Epoch 13/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 4143.3018 - val_loss: 24685.7930\n",
            "Epoch 14/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7617.6948 - val_loss: 37750.3945\n",
            "Epoch 15/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5015.3271 - val_loss: 38485.9688\n",
            "Epoch 16/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 21453.8379 - val_loss: 52722.0352\n",
            "Epoch 17/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4833.3755 - val_loss: 45124.3398\n",
            "Epoch 18/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6163.7964 - val_loss: 58002.9062\n",
            "Epoch 19/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4194.8271 - val_loss: 47545.2500\n",
            "Epoch 20/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5259.2363 - val_loss: 35314.5156\n",
            "Epoch 21/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24429.4414 - val_loss: 36662.4688\n",
            "Epoch 22/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6616.2422 - val_loss: 55186.9219\n",
            "Epoch 23/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12684.9531 - val_loss: 52193.2109\n",
            "Epoch 24/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5631.0625 - val_loss: 48431.7773\n",
            "Epoch 25/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8223.7852 - val_loss: 52727.0195\n",
            "Epoch 26/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2879.9836 - val_loss: 41382.3867\n",
            "Epoch 27/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2964.0359 - val_loss: 41080.6016\n",
            "Epoch 28/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4571.3906 - val_loss: 34610.4766\n",
            "Epoch 29/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4380.3267 - val_loss: 33917.2617\n",
            "Epoch 30/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4819.2520 - val_loss: 36100.3867\n",
            "Epoch 31/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7109.6470 - val_loss: 37779.3672\n",
            "Epoch 32/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5917.7271 - val_loss: 36095.3984\n",
            "Epoch 33/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8357.2949 - val_loss: 42109.9727\n",
            "Epoch 34/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 10602.0371 - val_loss: 54529.1211\n",
            "Epoch 35/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16683.2695 - val_loss: 38916.1055\n",
            "Epoch 36/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5217.5820 - val_loss: 35637.4727\n",
            "Epoch 37/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3661.8730 - val_loss: 39490.5430\n",
            "Epoch 38/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5310.1807 - val_loss: 30712.4180\n",
            "Epoch 39/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4956.2729 - val_loss: 34683.4883\n",
            "Epoch 40/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4286.2930 - val_loss: 34977.3125\n",
            "Epoch 41/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4249.9541 - val_loss: 50028.0547\n",
            "Epoch 42/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 10683.6807 - val_loss: 43632.1094\n",
            "Epoch 43/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10271.8281 - val_loss: 36609.1602\n",
            "Epoch 44/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5557.1328 - val_loss: 39700.6094\n",
            "Epoch 45/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5286.1353 - val_loss: 43105.6992\n",
            "Epoch 46/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3981.5762 - val_loss: 40271.8438\n",
            "Epoch 47/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11064.9473 - val_loss: 40067.0977\n",
            "Epoch 48/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4949.9634 - val_loss: 34546.1914\n",
            "Epoch 49/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12727.2754 - val_loss: 34703.5039\n",
            "Epoch 50/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3776.3257 - val_loss: 49713.1719\n",
            "Epoch 51/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6063.1089 - val_loss: 55798.7227\n",
            "Epoch 52/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6592.2510 - val_loss: 41339.7266\n",
            "Epoch 53/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5117.2607 - val_loss: 39049.0938\n",
            "Epoch 54/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15017.3105 - val_loss: 47483.7188\n",
            "Epoch 55/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5491.0425 - val_loss: 38459.7188\n",
            "Epoch 56/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4389.3408 - val_loss: 44436.7773\n",
            "Epoch 57/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5792.1660 - val_loss: 46594.2656\n",
            "Epoch 58/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9138.5908 - val_loss: 43874.5859\n",
            "Epoch 59/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7309.4033 - val_loss: 49414.6992\n",
            "Epoch 60/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4091.3916 - val_loss: 47017.8672\n",
            "Epoch 61/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4531.8687 - val_loss: 50508.0898\n",
            "Epoch 62/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13932.1143 - val_loss: 45716.5039\n",
            "Epoch 63/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7886.4541 - val_loss: 45195.1680\n",
            "Epoch 64/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5640.2314 - val_loss: 42768.2422\n",
            "Epoch 65/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5206.1138 - val_loss: 51183.8008\n",
            "Epoch 66/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4601.0508 - val_loss: 46048.2852\n",
            "Epoch 67/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2154.0334 - val_loss: 42531.2383\n",
            "Epoch 68/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9378.2812 - val_loss: 36029.5547\n",
            "Epoch 69/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8194.7100 - val_loss: 72214.2578\n",
            "Epoch 70/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4572.0415 - val_loss: 58631.9141\n",
            "Epoch 71/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4167.1797 - val_loss: 54196.2031\n",
            "Epoch 72/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17072.2285 - val_loss: 63498.8281\n",
            "Epoch 73/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 22351.7070 - val_loss: 43413.6758\n",
            "Epoch 74/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4032.8674 - val_loss: 43849.5469\n",
            "Epoch 75/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5338.0967 - val_loss: 48219.5039\n",
            "Epoch 76/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5062.5474 - val_loss: 46819.8398\n",
            "Epoch 77/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16353.7998 - val_loss: 37355.3555\n",
            "Epoch 78/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9624.1230 - val_loss: 54380.6953\n",
            "Epoch 79/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3820.3142 - val_loss: 46682.1797\n",
            "Epoch 80/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4053.1255 - val_loss: 34588.6367\n",
            "Epoch 81/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5163.7158 - val_loss: 37297.8867\n",
            "Epoch 82/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4844.8975 - val_loss: 51279.0664\n",
            "Epoch 83/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3109.8008 - val_loss: 58924.9102\n",
            "Epoch 84/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2758.0801 - val_loss: 57497.5820\n",
            "Epoch 85/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4011.9775 - val_loss: 53524.6680\n",
            "Epoch 86/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4902.3140 - val_loss: 51405.6523\n",
            "Epoch 87/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8142.8955 - val_loss: 46052.9883\n",
            "Epoch 88/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3094.3833 - val_loss: 36447.5664\n",
            "Epoch 89/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6705.7490 - val_loss: 44724.1367\n",
            "Epoch 90/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5864.6270 - val_loss: 45951.8750\n",
            "Epoch 91/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7203.8286 - val_loss: 54756.3594\n",
            "Epoch 92/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4468.5195 - val_loss: 40680.7695\n",
            "Epoch 93/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12041.2402 - val_loss: 35399.3086\n",
            "Epoch 94/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7705.5518 - val_loss: 38961.2578\n",
            "Epoch 95/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2900.8123 - val_loss: 45744.6289\n",
            "Epoch 96/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6744.7925 - val_loss: 42054.2852\n",
            "Epoch 97/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3841.7390 - val_loss: 55313.4648\n",
            "Epoch 98/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3945.4531 - val_loss: 54973.6562\n",
            "Epoch 99/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2103.0842 - val_loss: 43442.6953\n",
            "Epoch 100/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4666.5449 - val_loss: 59165.4297\n",
            "Epoch 101/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4182.3750 - val_loss: 55908.8906\n",
            "Epoch 102/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2708.5391 - val_loss: 58269.3242\n",
            "Epoch 103/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5310.2847 - val_loss: 64213.0547\n",
            "Epoch 104/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3134.9053 - val_loss: 63601.1719\n",
            "Epoch 105/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2782.0974 - val_loss: 64954.0312\n",
            "Epoch 106/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6298.5527 - val_loss: 48954.8438\n",
            "Epoch 107/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4129.1973 - val_loss: 43605.2852\n",
            "Epoch 108/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3839.2759 - val_loss: 35263.3594\n",
            "Epoch 109/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7962.6147 - val_loss: 41626.5352\n",
            "Epoch 110/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4016.7800 - val_loss: 49284.7578\n",
            "Epoch 111/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8610.3164 - val_loss: 41736.7500\n",
            "Epoch 112/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4029.9192 - val_loss: 40521.7383\n",
            "Epoch 113/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9523.1094 - val_loss: 55366.9922\n",
            "Epoch 114/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3608.0649 - val_loss: 42233.8750\n",
            "Epoch 115/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5072.4014 - val_loss: 28601.1777\n",
            "Epoch 116/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4516.3560 - val_loss: 30448.3887\n",
            "Epoch 117/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8790.3711 - val_loss: 42354.0586\n",
            "Epoch 118/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3366.6775 - val_loss: 48873.0391\n",
            "Epoch 119/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2914.6042 - val_loss: 43999.0000\n",
            "Epoch 120/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7179.4927 - val_loss: 31204.1113\n",
            "Epoch 121/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2482.3003 - val_loss: 27741.5156\n",
            "Epoch 122/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5973.3394 - val_loss: 33457.2695\n",
            "Epoch 123/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3550.3254 - val_loss: 32005.1465\n",
            "Epoch 124/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7708.2700 - val_loss: 33868.6289\n",
            "Epoch 125/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7539.5752 - val_loss: 31054.2598\n",
            "Epoch 126/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7622.1104 - val_loss: 22405.9453\n",
            "Epoch 127/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3979.7239 - val_loss: 40067.4805\n",
            "Epoch 128/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5399.8604 - val_loss: 33969.2070\n",
            "Epoch 129/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18211.8594 - val_loss: 31351.5996\n",
            "Epoch 130/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8229.7090 - val_loss: 28313.1191\n",
            "Epoch 131/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16032.1123 - val_loss: 36671.9297\n",
            "Epoch 132/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5454.9585 - val_loss: 40674.5195\n",
            "Epoch 133/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24607.8438 - val_loss: 54260.8242\n",
            "Epoch 134/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5513.9321 - val_loss: 54384.7500\n",
            "Epoch 135/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4869.7798 - val_loss: 49268.0039\n",
            "Epoch 136/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3218.1218 - val_loss: 47756.3281\n",
            "Epoch 137/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4852.4331 - val_loss: 37974.5977\n",
            "Epoch 138/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3111.2290 - val_loss: 38220.5820\n",
            "Epoch 139/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3830.8149 - val_loss: 33807.1289\n",
            "Epoch 140/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9682.0264 - val_loss: 39636.1094\n",
            "Epoch 141/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4570.6006 - val_loss: 34934.2930\n",
            "Epoch 142/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3970.6135 - val_loss: 40367.4297\n",
            "Epoch 143/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6690.0415 - val_loss: 30394.0117\n",
            "Epoch 144/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2361.9023 - val_loss: 30657.6152\n",
            "Epoch 145/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 4511.6909 - val_loss: 33977.5977\n",
            "Epoch 146/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8873.4453 - val_loss: 48221.4727\n",
            "Epoch 147/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5462.9048 - val_loss: 50042.0898\n",
            "Epoch 148/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6592.9438 - val_loss: 45736.8359\n",
            "Epoch 149/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2569.3352 - val_loss: 44466.9531\n",
            "Epoch 150/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14172.4902 - val_loss: 44936.8945\n",
            "Epoch 151/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3230.0732 - val_loss: 44041.4258\n",
            "Epoch 152/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5060.2446 - val_loss: 45216.9297\n",
            "Epoch 153/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5947.7734 - val_loss: 56673.9844\n",
            "Epoch 154/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8828.2217 - val_loss: 36838.3633\n",
            "Epoch 155/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5338.7983 - val_loss: 36332.8672\n",
            "Epoch 156/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4126.6240 - val_loss: 55397.2969\n",
            "Epoch 157/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12186.9092 - val_loss: 38938.5742\n",
            "Epoch 158/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15504.1719 - val_loss: 30316.5293\n",
            "Epoch 159/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16326.0898 - val_loss: 35621.8164\n",
            "Epoch 160/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3253.4485 - val_loss: 34536.2266\n",
            "Epoch 161/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6750.2544 - val_loss: 43804.9648\n",
            "Epoch 162/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3793.1345 - val_loss: 39381.6133\n",
            "Epoch 163/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4891.1670 - val_loss: 43634.5742\n",
            "Epoch 164/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10451.9199 - val_loss: 34967.2109\n",
            "Epoch 165/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5521.4639 - val_loss: 32985.0352\n",
            "Epoch 166/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3923.2373 - val_loss: 31806.0859\n",
            "Epoch 167/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11843.0684 - val_loss: 31094.7188\n",
            "Epoch 168/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5955.7114 - val_loss: 35328.9805\n",
            "Epoch 169/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4122.4609 - val_loss: 32335.6914\n",
            "Epoch 170/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13379.3467 - val_loss: 30981.6367\n",
            "Epoch 171/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4610.8091 - val_loss: 36720.2656\n",
            "Epoch 172/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4444.9395 - val_loss: 41370.8789\n",
            "Epoch 173/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3999.4834 - val_loss: 33724.9492\n",
            "Epoch 174/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3591.8069 - val_loss: 31828.5703\n",
            "Epoch 175/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5128.8467 - val_loss: 36011.1406\n",
            "Epoch 176/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2972.6174 - val_loss: 37570.7305\n",
            "Epoch 177/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4387.3096 - val_loss: 31633.5059\n",
            "Epoch 178/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5729.2407 - val_loss: 41301.4336\n",
            "Epoch 179/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5583.3311 - val_loss: 46705.1602\n",
            "Epoch 180/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3499.1519 - val_loss: 44477.3281\n",
            "Epoch 181/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9386.4688 - val_loss: 40290.2695\n",
            "Epoch 182/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18085.2715 - val_loss: 37544.8711\n",
            "Epoch 183/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3937.4973 - val_loss: 38789.7773\n",
            "Epoch 184/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4917.8975 - val_loss: 52615.6250\n",
            "Epoch 185/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8488.7920 - val_loss: 39472.3320\n",
            "Epoch 186/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6834.1616 - val_loss: 34712.4766\n",
            "Epoch 187/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13433.6348 - val_loss: 35455.8242\n",
            "Epoch 188/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3539.4956 - val_loss: 35711.3555\n",
            "Epoch 189/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6910.7051 - val_loss: 27651.3770\n",
            "Epoch 190/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11724.7002 - val_loss: 40768.8594\n",
            "Epoch 191/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14506.5205 - val_loss: 47202.2656\n",
            "Epoch 192/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3355.9783 - val_loss: 51913.9688\n",
            "Epoch 193/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7355.2959 - val_loss: 33177.9727\n",
            "Epoch 194/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3866.2515 - val_loss: 42393.3008\n",
            "Epoch 195/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7679.2070 - val_loss: 32712.3008\n",
            "Epoch 196/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3185.5479 - val_loss: 35514.2461\n",
            "Epoch 197/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3268.0374 - val_loss: 34040.3984\n",
            "Epoch 198/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3324.1025 - val_loss: 35922.5078\n",
            "Epoch 199/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3826.0029 - val_loss: 41824.6367\n",
            "Epoch 200/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5818.4409 - val_loss: 48382.5078\n",
            "Epoch 201/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6104.0952 - val_loss: 36814.4414\n",
            "Epoch 202/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3382.1953 - val_loss: 31522.1660\n",
            "Epoch 203/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4953.2271 - val_loss: 33043.4453\n",
            "Epoch 204/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4159.4688 - val_loss: 43104.7773\n",
            "Epoch 205/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5358.5010 - val_loss: 35619.6992\n",
            "Epoch 206/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4772.1899 - val_loss: 43320.8789\n",
            "Epoch 207/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7989.6851 - val_loss: 49209.9102\n",
            "Epoch 208/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7322.0054 - val_loss: 55431.8164\n",
            "Epoch 209/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20440.9238 - val_loss: 51989.7930\n",
            "Epoch 210/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3432.3025 - val_loss: 43389.8008\n",
            "Epoch 211/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3479.0359 - val_loss: 41921.3281\n",
            "Epoch 212/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4833.4668 - val_loss: 35477.2891\n",
            "Epoch 213/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3341.0293 - val_loss: 49725.2266\n",
            "Epoch 214/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 18197.1367 - val_loss: 39251.2344\n",
            "Epoch 215/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3715.3918 - val_loss: 63757.6875\n",
            "Epoch 216/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3700.7996 - val_loss: 42589.7461\n",
            "Epoch 217/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3254.8970 - val_loss: 38042.3203\n",
            "Epoch 218/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5502.9365 - val_loss: 33234.1914\n",
            "Epoch 219/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4078.5781 - val_loss: 35266.5625\n",
            "Epoch 220/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2492.2300 - val_loss: 49610.7500\n",
            "Epoch 221/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6428.5776 - val_loss: 39474.2656\n",
            "Epoch 222/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2331.5400 - val_loss: 40516.5352\n",
            "Epoch 223/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9709.3564 - val_loss: 54139.8945\n",
            "Epoch 224/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5295.4683 - val_loss: 33150.2070\n",
            "Epoch 225/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10276.2109 - val_loss: 48780.5586\n",
            "Epoch 226/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6572.4785 - val_loss: 33214.6445\n",
            "Epoch 227/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5146.3467 - val_loss: 44025.6055\n",
            "Epoch 228/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10012.9180 - val_loss: 49111.7383\n",
            "Epoch 229/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5321.3867 - val_loss: 38659.6133\n",
            "Epoch 230/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5046.5093 - val_loss: 43242.6797\n",
            "Epoch 231/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9174.9561 - val_loss: 34877.8906\n",
            "Epoch 232/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3830.6389 - val_loss: 32201.6582\n",
            "Epoch 233/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3952.4609 - val_loss: 27351.6172\n",
            "Epoch 234/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8203.8564 - val_loss: 39513.6094\n",
            "Epoch 235/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3328.1682 - val_loss: 39309.7617\n",
            "Epoch 236/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6336.1816 - val_loss: 35132.7109\n",
            "Epoch 237/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9771.3369 - val_loss: 39673.0117\n",
            "Epoch 238/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4270.2725 - val_loss: 40706.0859\n",
            "Epoch 239/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4209.7686 - val_loss: 38605.0898\n",
            "Epoch 240/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3076.9934 - val_loss: 39951.4727\n",
            "Epoch 241/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 4778.2441 - val_loss: 42109.6758\n",
            "Epoch 242/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8519.1504 - val_loss: 42728.6680\n",
            "Epoch 243/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4697.6162 - val_loss: 42745.7461\n",
            "Epoch 244/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4590.8477 - val_loss: 41711.1875\n",
            "Epoch 245/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6516.7710 - val_loss: 50660.0117\n",
            "Epoch 246/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16560.7598 - val_loss: 45531.8086\n",
            "Epoch 247/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2384.1304 - val_loss: 37166.2539\n",
            "Epoch 248/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4170.0522 - val_loss: 44842.6758\n",
            "Epoch 249/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 17339.0332 - val_loss: 34116.9375\n",
            "Epoch 250/250\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9071.2109 - val_loss: 35132.8711\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7af72e98ba50>"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 Predict & Evaluate\n",
        "y_pred = model.predict(X_test).flatten()\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"🔹 Neural Network Model RMSE:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH-szfnxdKU7",
        "outputId": "d4be4528-ba12-4403-ad98-6786736fdbdf"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "🔹 Neural Network Model RMSE: 90.6617825905372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 Recommendation Function\n",
        "def recommend_papers(query, top_n=10):\n",
        "    query_vec = vectorizer.transform([query])\n",
        "    similarities = cosine_similarity(query_vec, abstract_vectors).flatten()\n",
        "\n",
        "    if len(similarities) != len(df):\n",
        "        print(f\"⚠️ Warning: Similarity scores length ({len(similarities)}) does not match dataframe ({len(df)})\")\n",
        "        return None\n",
        "\n",
        "    df['similarity'] = similarities\n",
        "    df['score'] = df['similarity'] + df['pagerank'] + df['normalized_citations']\n",
        "\n",
        "    # ✅ Fix: Ensure authors are in readable format\n",
        "    df[\"authors\"] = df[\"authors\"].apply(lambda x: ', '.join(x) if isinstance(x, list) else str(x))\n",
        "    df[\"authors\"] = df[\"authors\"].fillna(\"Unknown\")  # Handle NaN values\n",
        "\n",
        "    # ✅ Ensure authors column is selected\n",
        "    top_papers = df.nlargest(top_n, 'score')[[\"Title\", \"Venue\", \"Year\", \"Score\"]]\n",
        "\n",
        "    print(\"\\n🔹 **Top Recommended Research Papers** 🔹\\n\")\n",
        "    print(top_papers.to_string(index=False))\n",
        "\n",
        "    return top_papers"
      ],
      "metadata": {
        "id": "4U61LfadUBbO"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# 🔹 Recommendation Function\n",
        "def recommend_papers(query, top_n=10):\n",
        "    query_vec = vectorizer.transform([query])\n",
        "    similarities = cosine_similarity(query_vec, abstract_vectors).flatten()\n",
        "\n",
        "    if len(similarities) != len(df):\n",
        "        print(f\"⚠️ Warning: Similarity scores length ({len(similarities)}) does not match dataframe ({len(df)})\")\n",
        "        return None\n",
        "\n",
        "    df['similarity'] = similarities\n",
        "    df['score'] = df['similarity'] + df['pagerank'] + df['normalized_citations']\n",
        "\n",
        "    # Drop or ignore authors\n",
        "    top_papers = df.nlargest(top_n, 'score')[[\"title\", \"venue\", \"year\", \"score\"]]\n",
        "\n",
        "    print(\"\\n🔹 **Top Recommended Research Papers** 🔹\\n\")\n",
        "    print(tabulate(top_papers, headers=\"keys\", tablefmt=\"fancy_grid\", showindex=False))\n",
        "\n",
        "    return top_papers"
      ],
      "metadata": {
        "id": "BAHjLwnUcf3L"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔍 **User Input**\n",
        "user_input = input(\"\\n🔍 Enter research topic: \")\n",
        "recommended_papers = recommend_papers(user_input, top_n=10)"
      ],
      "metadata": {
        "id": "cctuFJ-m3YNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1155ab5-7c0d-45c0-af70-7d8d35ff91e5"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Enter research topic: Big Data\n",
            "\n",
            "🔹 **Top Recommended Research Papers** 🔹\n",
            "\n",
            "╒═════════════════════════════════════════════════════════════════════════════════════════════════════════════╤════════════════════════════════════════════════╤════════╤══════════╕\n",
            "│ title                                                                                                       │ venue                                          │   year │    score │\n",
            "╞═════════════════════════════════════════════════════════════════════════════════════════════════════════════╪════════════════════════════════════════════════╪════════╪══════════╡\n",
            "│ New Directions in Cryptography                                                                              │ IEEE Transactions on Information Theory        │   1976 │ 1.00011  │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────┼────────┼──────────┤\n",
            "│ A relational model of data for large shared data banks                                                      │ Communications of The ACM                      │   1970 │ 0.841717 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────┼────────┼──────────┤\n",
            "│ The Concept of a Linguistic Variable and its Application to Approximate Reasoning-I                         │ Information Sciences                           │   1975 │ 0.722857 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────┼────────┼──────────┤\n",
            "│ Architecture of a Hardware Data Interpreter                                                                 │ IEEE Transactions on Computers                 │   1979 │ 0.714129 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────┼────────┼──────────┤\n",
            "│ Data abstractions for data bases                                                                            │ international conference on management of data │   1976 │ 0.511996 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────┼────────┼──────────┤\n",
            "│ Nearest neighbor pattern classification                                                                     │ IEEE Transactions on Information Theory        │   1967 │ 0.510607 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────┼────────┼──────────┤\n",
            "│ How to share a secret                                                                                       │ Communications of The ACM                      │   1979 │ 0.486157 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────┼────────┼──────────┤\n",
            "│ A Picture-Building System                                                                                   │ IEEE Transactions on Software Engineering      │   1976 │ 0.478629 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────┼────────┼──────────┤\n",
            "│ Principles of artificial intelligence                                                                       │ nan                                            │   1980 │ 0.471664 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────┼────────┼──────────┤\n",
            "│ A data management system for time-shared file processing using a cross-index file and self-defining entries │ nan                                            │   1966 │ 0.462794 │\n",
            "╘═════════════════════════════════════════════════════════════════════════════════════════════════════════════╧════════════════════════════════════════════════╧════════╧══════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0xLuG26CmZq",
        "outputId": "91493d65-faa9-496b-9e9c-b3ddb6566045"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 UI-Based Paper Recommender System for Google Colab\n",
        "# ✅ Must run in Google Colab\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "import gradio as gr\n",
        "\n",
        "# 🔹 Safe literal eval for list columns\n",
        "def safe_literal_eval(val):\n",
        "    try:\n",
        "        return ast.literal_eval(val) if isinstance(val, str) else []\n",
        "    except (SyntaxError, ValueError):\n",
        "        return []\n",
        "\n",
        "# 🔹 Preprocessing Function\n",
        "def preprocess_data(df):\n",
        "    df[\"references\"] = df[\"references\"].apply(safe_literal_eval)\n",
        "    df[\"authors\"] = df[\"authors\"].apply(safe_literal_eval)\n",
        "\n",
        "    df[\"normalized_citations\"] = MinMaxScaler().fit_transform(df[['n_citation']])\n",
        "\n",
        "    centrality_features = [\"betweenness\", \"closeness\", \"degree\", \"eigenvector\"]\n",
        "    for feature in centrality_features:\n",
        "        df[feature] = df[feature].fillna(0)\n",
        "\n",
        "    if \"pagerank\" not in df.columns:\n",
        "        G_paper = nx.DiGraph()\n",
        "        for _, row in df.iterrows():\n",
        "            paper_id = row[\"title\"]\n",
        "            for ref in row[\"references\"]:\n",
        "                G_paper.add_edge(paper_id, ref)\n",
        "        pagerank_scores = nx.pagerank(G_paper)\n",
        "        df[\"pagerank\"] = df[\"title\"].map(pagerank_scores).fillna(0)\n",
        "\n",
        "    if \"h_index\" not in df.columns:\n",
        "        def compute_hindex(author_papers):\n",
        "            citations = sorted(author_papers, reverse=True)\n",
        "            h_index = sum(c >= i+1 for i, c in enumerate(citations))\n",
        "            return h_index\n",
        "\n",
        "        author_hindex = {}\n",
        "        for _, row in df.iterrows():\n",
        "            for author in row[\"authors\"]:\n",
        "                if author not in author_hindex:\n",
        "                    author_hindex[author] = []\n",
        "                author_hindex[author].append(row[\"n_citation\"])\n",
        "\n",
        "        df[\"h_index\"] = df[\"authors\"].apply(lambda authors: np.mean([compute_hindex(author_hindex[a]) for a in authors]) if authors else 0)\n",
        "\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    df = df.dropna(subset=[\"n_citation\"])\n",
        "\n",
        "    features = [\"normalized_citations\", \"pagerank\", \"h_index\", \"betweenness\", \"closeness\", \"degree\", \"eigenvector\"]\n",
        "    df[features] = df[features].fillna(0)\n",
        "    return df, features\n",
        "\n",
        "# 🔹 Train Neural Network\n",
        "def train_model(df, features):\n",
        "    X = df[features]\n",
        "    y = df[\"n_citation\"].astype(float)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        BatchNormalization(), Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(), Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
        "    return model\n",
        "\n",
        "# 🔹 Main Recommend Function\n",
        "def build_recommender(df, model, vectorizer, abstract_vectors):\n",
        "    def recommend(query):\n",
        "        query_vec = vectorizer.transform([query])\n",
        "        sim_scores = cosine_similarity(query_vec, abstract_vectors).flatten()\n",
        "        df[\"similarity\"] = sim_scores\n",
        "        df[\"score\"] = df[\"similarity\"] + df[\"pagerank\"] + df[\"normalized_citations\"]\n",
        "        df[\"authors\"] = df[\"authors\"].apply(lambda x: ', '.join(x) if isinstance(x, list) else str(x))\n",
        "        df[\"authors\"] = df[\"authors\"].fillna(\"Unknown\")\n",
        "        top_papers = df.nlargest(5, \"score\")[[\"title\", \"authors\", \"venue\", \"year\", \"score\"]]\n",
        "        return top_papers\n",
        "    return recommend\n",
        "\n",
        "# 🔹 Load CSV in Colab and Initialize\n",
        "# Run in a Colab cell before UI: from google.colab import files; uploaded = files.upload()\n",
        "df = pd.read_csv(\"paper_dataset.csv\")\n",
        "df, features = preprocess_data(df)\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "abstract_vectors = vectorizer.fit_transform(df[\"abstract\"].fillna(\"\"))\n",
        "model = train_model(df, features)\n",
        "recommender = build_recommender(df, model, vectorizer, abstract_vectors)\n",
        "\n",
        "# 🔹 Build Gradio UI\n",
        "with gr.Blocks(theme=gr.themes.Soft(), css=\"body {background: #fefefe; font-family: 'Segoe UI';}\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🔍 AI-Powered Research Paper Recommender\n",
        "    Enter your research interest and get top 5 most relevant papers 📚✨\n",
        "    \"\"\")\n",
        "    query = gr.Textbox(label=\"Enter Research Topic\", placeholder=\"e.g., Neural networks for text generation\")\n",
        "    output = gr.Dataframe(headers=[\"Title\", \"Authors\", \"Venue\", \"Year\", \"Score\"], wrap=True)\n",
        "    btn = gr.Button(\"Recommend Papers\")\n",
        "    btn.click(fn=recommender, inputs=query, outputs=output)\n",
        "\n",
        "# 🔹 Launch in Colab\n",
        "demo.launch(debug=False, share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "Z4tjTmzXCmWM",
        "outputId": "48861ec0-3357-461a-e3f3-1d50037ed85a"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4957d031fbb3a3bdcd.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4957d031fbb3a3bdcd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    }
  ]
}